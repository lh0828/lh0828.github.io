<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>LLM basic knowledge</title>
    <link href="/2025/11/30/LLM%20basic%20knowledge/"/>
    <url>/2025/11/30/LLM%20basic%20knowledge/</url>
    
    <content type="html"><![CDATA[<p>【<a href="https://datawhalechina.github.io/llm-cookbook/#/">面向开发者的LLM教程</a>】</p><p>LLM是通过预测下一个词的的监督学习方式进行训练的。具体来说，首先准备一个包含数百亿甚至更多词的大规模文本数据集。然后，可以从这些文本中提取句子或句子片段作为模型输入。模型会根据当前输入 Context 预测下一个词的概率分布。通过不断比较模型预测和实际的下一个词，并更新模型参数最小化两者差异,语言模型逐步掌握了语言的规律，学会了预测下一个词。</p><p>在训练过程中,研究人员会准备大量句子或句子片段作为训练样本,要求模型一次次预测下一个词，通过反复训练促使模型参数收敛，使其预测能力不断提高。经过在海量文本数据集上的训练，语言模型可以达到十分准确地预测下一个词的效果。这种<strong>以预测下一个词为训练目标的方法使得语言模型获得强大的语言生成能力</strong>。</p><p>思考：这个和当初<strong>Alpha Go</strong>生成下一步棋的方式是不是有异曲同工之妙？</p><p><a href="https://github.com/RUCAIBox/LLMSurvey?tab=readme-ov-file">https://github.com/RUCAIBox/LLMSurvey?tab=readme-ov-file</a></p><p>input (prompt) -&gt; fn{LLM} -&gt; output</p><h2 id="历史发展"><a href="#历史发展" class="headerlink" title="历史发展"></a>历史发展</h2><p>大语言模型发展主要经历了统计语言模型 –&gt; 神经语言模型 –&gt; 预训练语言模型 –&gt; 大语言模型四个阶段</p><p>图片引用自<a href="https://cleaner.love/">Cleaner 知识库</a></p><p><img src="/Users/liuhe/Desktop/54ef071380add26b345f939d85dcd39b.png" alt="54ef071380add26b345f939d85dcd39b"></p><p>语言模型发展史</p><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="Token"><a href="#Token" class="headerlink" title="Token"></a>Token</h3><p>Token的概念相当于文字，一个中文文字对应一个token，比如我爱你，对应三个token：我+爱+你；一个英文的字符对应一个token，比如love，而icecream对应两个token：ice+cream。</p><p>联系理解，计算机理解数据的形式是<strong>比特流</strong>，那么类比联想理解，LLM理解数据的“字节”就是一个Token。</p><h3 id="预训练"><a href="#预训练" class="headerlink" title="预训练"></a>预训练</h3><p>使用大语言模型在<strong>大规模语料</strong>上进行预训练，大语言模型可以获得通用的语言理解与生成能力，掌握较为广泛的世界知识，具备解决众多下游任务的性能潜力。</p><p>预训练大模型类比机器学习的训练模式，其实就是通过算法将模型在训练集上先进行训练</p><h3 id="微调"><a href="#微调" class="headerlink" title="微调"></a>微调</h3><p>指令微调是指使用自然语言形式的数据对预训练后的大语言模型进行<strong>参数微调</strong>，它是增强和激活大语言模型特定能力的重要方法之一。通过使用任务输入与输出的配对数据进行模型训练，可以使语言模型掌握通过问答形式进行任务求解的能力和较强的指令遵循能力，并且能够无需下游任务的训练样本或者示例就可以解决训练中未见过的任务。</p><h3 id="对齐"><a href="#对齐" class="headerlink" title="对齐"></a>对齐</h3><p>经过大规模的预训练和有监督指令微调，大语言模型具备了解决各种任务的通用能力和指令遵循能力，但是同时也可能生成<code>有偏见的</code>、<code>冒犯的</code>以及<code>事实错误的</code>文本内容。这些潜在的有害行为，可能在下游应用中产生严重的影响与危害，进一步被恶意使用者进行放大与利用。因此，在大语言模型的学习过程中，如何确保大语言模型的行为与人类价值观、人类真实意图和社会伦理相一致成为了一个 关键研究问题，通常称这一研究问题为<strong>人类对齐</strong>。</p><h3 id="泛化"><a href="#泛化" class="headerlink" title="泛化"></a>泛化</h3><p>模型泛化是指一些模型可以应用（泛化）到其他场景，通常为采用迁移学习、微调等手段实现泛化。</p><h3 id="涌现"><a href="#涌现" class="headerlink" title="涌现"></a>涌现</h3><p>模型规模达到一定阈值以上后，会在多步算术、大学考试、单词释义等场景的准确性显著提升，称为涌现。</p><h2 id="RAG与微调"><a href="#RAG与微调" class="headerlink" title="RAG与微调"></a>RAG与微调</h2><p>目前的大模型都是预训练语言模型 LLaMA、GPT4o、o1-mini</p><ul><li>互联网公开的海量数据</li><li>私有化数据</li></ul><p>针对互联网数据无法及时更新与专业领域私有化数据的解决方案：</p><ul><li>RAG-检索增强生成：数据（语料）数据大部分是文献资料、文档</li><li>SFT-微调：QA-法律咨询、心理诊断等一问一答数据标签归类，微调出一个适用场景的垂直场景</li></ul><p>RAG缺点：</p><p>检索出来的文档片段不完整，重排序</p><p>对于系统延迟低场景(检索器检索)</p><p>Embeding Model-嵌入</p><p>将文本转换成一组N维的浮点数，文本向量又叫做Embedings</p><p>向量之间可以计算距离，距离的远近对应语义的相似性</p><p>以前的工程中，keywords、sql &#x3D; 精确匹配，使用关系型数据库进行存储。现在文本嵌入、图片嵌入等 &#x3D; 距离相似度匹配，使用向量数据库存储</p><p>原始文档 -》embedded</p><p>query -》embedded</p><p>必须使用同一个Embedded model</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello Hexo</title>
    <link href="/2025/11/28/Hello%20Word/"/>
    <url>/2025/11/28/Hello%20Word/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>!</p><p>终于搭建成功，值得纪念的日子，今天把之前写的内容全部成功迁移到了新的平台上面。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;stdlib.h&gt;</span></span><br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> std;<br><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;<br>  cout &lt;&lt; welcome to hexo! &lt;&lt; endl;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Dream car</title>
    <link href="/2025/11/05/Dream%20car/"/>
    <url>/2025/11/05/Dream%20car/</url>
    
    <content type="html"><![CDATA[<p>2025年11月4日，星期二，晴天☀️</p><p>等待已久的梦中情车，今天终于提了。上周三请假回家，想着能体验一下提车的感觉，但因为种种原因没有提车，周日就回学校了😭。</p><p>奥迪A6，多少男人的向往，许多普通人遥不可及的梦。想起家里第一辆车还是在10年年底买的，应该是花了5万左右，到现在整整15年了。当时提车后还有人问我奶奶是否给我父亲添钱了(因为爷爷是退休校长，有退休金)，言外之意就是父亲自己没有能力买这台车。要说人还是得有一股子劲，较劲，这个较劲不是钻牛角尖，更是默默的打拼奋斗，不为别的，就为自己，这么多年也是见证了父母的不易，生活一点点的变好。以前感觉是朋友多了路好走，但现在感觉是路好走了朋友多，这就是人性吧，自立自强，比什么都强。</p><p>我和父亲的关系更像是“中式父子的关系”，言传很少，更多的是身教。提车时父亲并没有像一些人一样，发朋友圈、所谓的提车仪式等，父亲是一个很低调的人，但是做事心里非常有数，这也是他常说的低调做人，高调做事。他是他们那一辈的老大哥，家族里的一些红白事小的伯伯们都会和他商量，我也是我这一辈的大哥，处理事情的能力还需要培养，这东西得在事上练。</p><p>但现在一想，当我坐在这台车的时候，喜悦不会很多，更多的是压力，自己不是富二代，是土生土长，从农村出来的，怕的是自己以后没有能力换更好的车，这就是上限。一个家庭或家族的兴盛，不是靠一代人的努力就能实现的，而是靠几代人接力去不断变好。三十年河东，三十年河西，希望自己能够将这份压力转换成动力，把我这一棒接好，走好，人生没有一帆风顺的，只是希望在河东的时间能长些，不至于到河西的时候无能为力。</p><p>努力吧，希望多年以后自己换车的时候也能够来一句：全款，拿下！</p><p><img src="D:\Myblog\blog\source\img\4bc151c43855e84d91d21366615dfecf.png" alt="4bc151c43855e84d91d21366615dfecf"></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Multimodal RAG Systems</title>
    <link href="/2025/10/22/Multimodal%20RAG%20Systems/"/>
    <url>/2025/10/22/Multimodal%20RAG%20Systems/</url>
    
    <content type="html"><![CDATA[<h1 id="A-Comprehensive-Guide-to-Building-Multimodal-RAG-Systems"><a href="#A-Comprehensive-Guide-to-Building-Multimodal-RAG-Systems" class="headerlink" title="A Comprehensive Guide to Building Multimodal RAG Systems"></a>A Comprehensive Guide to Building Multimodal RAG Systems</h1><p>本篇博文的主要内容是对一篇综述性博客文章()的翻译阅读与总结。通过阅读本篇文章，理清楚多模态RAG的基本概念与应用场景、部署方式、工作流程。</p><p>RAG系统的优势是可以整合自身数据并增强LLM的智力，对于问题给出更多精确的回答。然而，关键的限制就是RAG系统仅仅是它仅适用于文本数据。 许多现实世界的数据本质上是多模态的，是文本、图像、表格等形式的混合。</p><p>该篇综述的主要目的就是着眼构建一个多模态的RAG系统，使用智能数据转换和多模态LLM解决混合数据格式。</p><h2 id="传统的RAG系统"><a href="#传统的RAG系统" class="headerlink" title="传统的RAG系统"></a>传统的RAG系统</h2><p>RAG系统架构通常包括：</p><ol><li>数据处理和索引</li><li>检索和响应生成</li></ol><h3 id="数据处理和索引"><a href="#数据处理和索引" class="headerlink" title="数据处理和索引"></a>数据处理和索引</h3><p>加载文档中的文本内容-&gt;将大型文本元素拆分为较小的块-&gt;使用嵌入器模型将它们转换为嵌入-&gt;将块和嵌入存储到矢量数据库中</p><p><a href="https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/unnamed-5.webp"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/unnamed-5.webp" alt="建立索引"></a></p><p>建立索引</p><h3 id="检索和响应生成"><a href="#检索和响应生成" class="headerlink" title="检索和响应生成"></a>检索和响应生成</h3><p>用户提问-&gt;文档检索-&gt;提示-&gt;LLM-&gt;回答</p><p>从向量数据库中检索与输入问题相似的相关文本文档块，然后将问题和上下文文档块发送到LLM以生成人类。</p><p><a href="https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/unnamed-1-3.webp"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/unnamed-1-3.webp" alt="检索生成"></a></p><p>检索生成</p><h2 id="传统RAG系统的限制"><a href="#传统RAG系统的限制" class="headerlink" title="传统RAG系统的限制"></a>传统RAG系统的限制</h2><ul><li>无法获悉实时数据</li><li>系统仅会利用好我们自身向量数据库中的数据</li><li>大部分RAG系统仅仅致力于文本数据的检索和生成</li><li>传统的LLMs 仅仅处理文本内容去生成回答</li><li>无法利用多模态数据进行工作</li></ul><h2 id="什么是多模态？"><a href="#什么是多模态？" class="headerlink" title="什么是多模态？"></a>什么是多模态？</h2><p>Multimodal data is essentially data belonging to multiple modalities.</p><p>多模态数据本质上是属于多种模态的数据。 模态的正式定义来自人机交互 (HCI) 系统的背景，其中模态被称为计算机和人类之间的单个独立输入和输出通道的分类（更多详细信息请参阅维基百科）。 常见的计算机-人类模式包括以下内容：</p><p>文本：Input and output through written language(e.g., chat interfaces).</p><p>语音：Voice-based interaction(e.g., voice assistants).</p><p>视频：Image and video processing for visual recognition (e.g., face detection).</p><p>手势：Hand and body movement tracking(e.g., gesture controls).</p><p>触控：Haptic feedback and touchscreens.</p><p>音频：Sound-based signals (e.g., music recognition, alerts).</p><p>生物识别：Interaction through physiological data (e.g., eye-tracking, fingerprints).</p><p>本综述重点关注处理文本、图像和表格。 理解此类数据所需的关键组件之一是多模态大语言模型 (LLM)。</p><p>多模态的本质是混合了多种多种模式和格式的数据：</p><p><a href="https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/unnamed-2_11zon.webp"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/unnamed-2_11zon.webp" alt="多模态数据"></a></p><p>多模态数据</p><h2 id="什么是多模态大语言模型？"><a href="#什么是多模态大语言模型？" class="headerlink" title="什么是多模态大语言模型？"></a>什么是多模态大语言模型？</h2><p>多模态大语言模型 (LLM) 本质上是基于 Transformer 的 LLM，已针对多模态数据进行预训练和微调，以分析和理解各种数据格式，包括文本、图像、表格、音频和视频。</p><p><a href="https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/unnamed-3-2.webp"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/unnamed-3-2.webp" alt="MLLMs"></a></p><p>MLLMs</p><p>理想情况下，真正的多模态模型不仅应该能够理解混合数据格式，还应该生成相同的数据格式。</p><p>文生图、图生文、文生音、文生视频</p><p>多模态编码阶段：</p><p>利用现有的成熟模型对各种模式的输入进行编码。</p><p>LLM理解和响应阶段</p><p>LLM被用作NExT GPT的核心代理。从技术上讲，他们采用Vicuna LLM，该LLM<strong>将来自不同模态的表示作为输入</strong>，并对<strong>输入进行语义理解和推理</strong>。它输出1）直接的文本响应和2）每种模态的<strong>信号标记</strong>，这些标记用作指示<strong>解码层是否生成多模态内容以及如果是则生成什么内容的指令</strong>。</p><p>多模态生成阶段</p><p>从LLM（如果有的话）<strong>接收具有特定指令的多模态信号</strong>，<strong>基于Transformer的输出投影层将信号令牌表示映射到后续多模态解码器可以理解的表示中</strong>。从技术上讲，他们采用了不同模态代的现成潜在条件<strong>扩散模型</strong>，即用于图像合成的稳定扩散（SD）、用于视频合成的Zeroscope和用于音频合成的AudioLDM。</p><p>目前，大多数可供实际使用的多模态LLM都是片面的，这意味着它们可以理解混合数据格式，但只能生成文本响应。</p><p><strong>GPT-4V &amp; GPT-4o</strong> (OpenAI):</p><p><strong>Gemini</strong> (Google):</p><p><strong>Claude</strong> (Anthropic):</p><p>想要构建完全开源的解决方案或担心数据隐私或延迟并更喜欢在内部本地托管所有内容，可以借助目前最流行的开放和开源多式联运模型构建：</p><p>LLaVA-NeXT: An open-source multimodal model with capabilities to work with text, images and also video, which an improvement on top of the popular LLaVa model</p><p>PaliGemma: A vision-language model from Google that integrates both image and text processing, designed for tasks like optical character recognition (OCR), object detection, and visual question answering (VQA).</p><p>Pixtral 12B: An advanced multimodal model from Mistral AI with 12 billion parameters that can process both images and text. Built on Mistral’s Nemo architecture, Pixtral 12B excels in tasks like image captioning and object recognition.</p><p>目前为止最为强大的多模态模型是Open-AI的GPT-4.o</p><h2 id="多模态RAG系统的工作流"><a href="#多模态RAG系统的工作流" class="headerlink" title="多模态RAG系统的工作流"></a>多模态RAG系统的工作流</h2><p>多模态RAG系统的构建流程与本篇博客的构建选择：</p><p><a href="https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/unnamed-4-2.webp"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/unnamed-4-2.webp" alt="workflow"></a></p><p>workflow</p><p>不好理解的一部分？</p><p>端到端的工作流：</p><p>如何去理解Summary？为什么图像、表格、和文本中在嵌入的时候都变成了Image Summary、Table Summary、Text Summary？</p><p>Option 1：</p><p>选择1缺陷的原因是多模态嵌入模型通常无法对这些视觉图像中的数字等粒度信息进行编码，并将其压缩为有意义的嵌入。</p><p>Option 2：</p><p>选项 2 受到严重限制，因为我们最终不会在该系统中使用图像，即使它可能包含有价值的信息，并且它不是真正的多模式 RAG 系统。</p><p>Option 3：</p><p>将继续使用选项 3 作为我们的多模态RAG 系统工作流程。 在此工作流程中，我们将从图像、表格以及可选的文本块中创建摘要，并使用多向量检索器，这可以帮助根据相应的原始图像、表格和文本元素映射和检索原始图像、表格和文本元素。</p><h2 id="Multi-Vector-Retrieval-Workflow"><a href="#Multi-Vector-Retrieval-Workflow" class="headerlink" title="Multi-Vector Retrieval Workflow"></a>Multi-Vector Retrieval Workflow</h2><p>考虑到我们将在上一节中讨论的工作流程，对于我们的检索工作流程，我们将使用如下图所示的多向量检索器，正如 LangChain 博客中推荐和提到的那样。 多向量检索器的主要目的是充当包装器，并帮助将每个文本块、表格和图像摘要<strong>映射到</strong>实际的文本块、表格和图像元素，然后可以在检索期间获得这些内容。</p><p><a href="https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/unnamed-5-2.webp"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/unnamed-5-2.webp" alt="多向量检索器"></a></p><p>多向量检索器</p><p>首先使用 Unstructed 等文档解析工具分别提取文本、表格和图像元素。 然后，我们将<strong>把每个提取的元素传递到 LLM 中，并生成详细的文本摘要</strong>，如上所示。 接下来，我们将使用任何流行的<strong>嵌入器模型</strong>（例如 OpenAI Embedders）将<strong>摘要及其嵌入存储到向量数据库</strong>中。 我们还将每个摘要的相应原始文档元素（文本、表格、图像）存储在文档存储中，文档存储可以是任何数据库平台，例如 Redis。</p><p>当用户提出问题时，首先，多向量检索器检索相关摘要，这些摘要在语义（嵌入）相似性方面与问题相似，然后使用公共的 doc_ids、原始文本、表格和图像 返回的元素将进一步传递给 RAG 系统的 LLM 作为回答用户问题的上下文。</p><h2 id="多模态RAG的架构细节"><a href="#多模态RAG的架构细节" class="headerlink" title="多模态RAG的架构细节"></a>多模态RAG的架构细节</h2><ol><li>Load all documents and use a document loader like <strong>unstructured.io</strong> to extract text chunks, image, and tables.</li><li>If necessary, convert HTML tables to markdown; they are often very effective with LLMs</li><li>Pass each text chunk, image, and table into a multimodal LLM like GPT-4o and get a detailed summary.</li><li>Store summaries in a vector DB and the raw document pieces in a document DB like Redis</li><li>Connect the two databases with a common document_id using a multi-vector retriever to identify which summary maps to which raw document piece.</li><li>Connect this multi-vector retrieval system with a multimodal LLM like GPT-4o.</li><li>Query the system, and based on similar summaries to the query, get the raw document pieces, including tables and images, as the context.</li><li>Using the above context, generate a response using the multimodal LLM for the question.</li></ol><p>1.加载所有文档，并使用类似unstructure.io的文档加载器提取文本块、图像和表格。</p><p>2.如有必要，将HTML表格转换为markdown；他们通常对LLM非常有效</p><p>3.将每个文本块、图像和表格传递到GPT-4o等多模式LLM中，并获得详细的摘要。</p><p>4.将摘要存储在向量数据库中，将原始文档片段存储在Redis等文档数据库中</p><p>5.使用多向量检索器使用公共document_id连接两个数据库，以识别哪个摘要映射到哪个原始文档块。</p><p>6.将这个多向量检索系统与GPT-4o等多模态LLM连接起来。</p><p>7.查询系统，并根据与查询类似的摘要，获取原始文档片段，包括表格和图像，作为上下文。</p><p>8.使用上述上下文，使用多模态LLM生成问题的答案。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>抉择本身就是向前吧</title>
    <link href="/2025/10/10/%E6%8A%89%E6%8B%A9%E6%9C%AC%E8%BA%AB%E5%B0%B1%E6%98%AF%E5%90%91%E5%89%8D%E5%90%A7/"/>
    <url>/2025/10/10/%E6%8A%89%E6%8B%A9%E6%9C%AC%E8%BA%AB%E5%B0%B1%E6%98%AF%E5%90%91%E5%89%8D%E5%90%A7/</url>
    
    <content type="html"><![CDATA[<h2 id="选择与看待结果"><a href="#选择与看待结果" class="headerlink" title="选择与看待结果"></a>选择与看待结果</h2><p>选择不分对错，抉择本身就是向前吧！</p><p>健健康康、内心阳光；事物都是在波动、曲折中发展的，无论结果如何，都要保持好心态。</p><p>尊重不同的声音，调整自己的状态。</p><p>结果当然重要，符合自己的预期，那得开心死；但是，结果如果不达预期，就不正常了吗？就不合理了吗？存在即合理啊，只是没达到你自己的预期，你会失落、会感到遗憾、会不开心。但是，没有达到预期，自己就没有一点问题吗？我想自身还是有很大问题的，而且不要过多的去抱怨周围的环境。</p><h2 id="要勇敢"><a href="#要勇敢" class="headerlink" title="要勇敢"></a>要勇敢</h2><p>要勇敢，但是勇敢的方式不要有攻击性，这还是要慢慢改、慢慢学的。</p><h2 id="爱"><a href="#爱" class="headerlink" title="爱"></a>爱</h2><p>好好爱自己、好好爱家人，爱人先爱己，勿忘心安。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>RAG for LLM - A survey</title>
    <link href="/2025/09/25/RAG%20for%20LLM%20-%20A%20survey/"/>
    <url>/2025/09/25/RAG%20for%20LLM%20-%20A%20survey/</url>
    
    <content type="html"><![CDATA[<h1 align="center">RAG for LLM - A survey</h1><p>论文题目：</p><p>Retrieval-Augmented Generation for Large Language Models: A Survey</p><p>论文链接：</p><p><a href="https://arxiv.org/abs/2312.10997">https://arxiv.org/abs/2312.10997</a></p><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h3><p>在LLM得到广泛应用的同时，对于LLM幻觉、过时知识、不透明、不可追踪的推理过程仍然面临巨大挑战。</p><p>可行的解决方式：RAG-检索生成增强</p><p>方式：连接外部数据库- RAG synergistically merges LLMs’ intrinsic knowledge with the vast, dynamic repositories of external databases.</p><p>RAG paradigms （RAG三大范式）：</p><ul><li>Naive RAG</li><li>Advanced RAG</li><li>Modular RAG</li></ul><p>文章重点强调了嵌入在RAG系统中的关键组件，提高了对RAG系统的理解。此外文章也给出了对于RAG系统的最新评估标准和框架。</p><h3 id="Introduction-RAG在大模型阶段的发展轨迹"><a href="#Introduction-RAG在大模型阶段的发展轨迹" class="headerlink" title="Introduction-RAG在大模型阶段的发展轨迹"></a>Introduction-RAG在大模型阶段的发展轨迹</h3><p>RAG技术最初与Transformer架构相吻合，通过增加外部知识库，在早期阶段用于细化预训练技术（pre-training）。</p><p>随着ChatGPT的兴起，大语言模型在长上下文的理解中展现出了强大能力。</p><p>RAG研究转向在推理阶段为LLM提供更好的信息，以回答更复杂和知识密集型的任务，导致RAG研究的快速发展。</p><p>后续随着研究进一步深入，RAG技术不再局限于推理阶段而是开始更多的和<strong>微调</strong>技术相结合。</p><p>总结：<strong>预训练-推理-微调</strong></p><p>RAG技术本身经历了快速发展，但是目前仍然没有对RAG系统发展的清楚阐述，这篇文章的写作目的之一就是填补这一空白，去为读者绘制RAG发展路径并评估他未来的发展路径。</p><p>文章旨在阐明检索增强技术的演变，评估各种方法在各自上下文中的优点和缺点，并推测即将到来的趋势和创新。</p><p>本文的主要贡献：</p><ul><li>系统性回顾了RAG最新的方法、技术，描述了RAG三大范式的演变，将RAG研究置于LLM前景中</li><li>识别并阐明了RAG的三大核心技术：Retrieval、Generation、Augmentation，阐明了这些组件如何协同形成有效的RAG框架</li><li>总结了RAG的当前评估方法，涵盖了26个任务，近50个数据集，概述了评估目标和指标，以及当前的评估基准和工具。预计RAG的未来方向，强调应对当前挑战的潜在增强。</li></ul><p>通过认真阅读、分析原文后，应该可以对本文的三大贡献进行连贯复述。</p><h3 id="Sectionll-RAG三大范式"><a href="#Sectionll-RAG三大范式" class="headerlink" title="Sectionll-RAG三大范式"></a>Sectionll-RAG三大范式</h3><h4 id="Naive-RAG"><a href="#Naive-RAG" class="headerlink" title="Naive RAG"></a>Naive RAG</h4><p>indexing</p><p>索引编排阶段会将所有类型的文档（PDF、Word、Markdown）转换为统一的文本格式。之后，为了使用语言模型的文本限制，“格式化”后的文本会被切分成chunks，使用嵌入模型，这些chunks会被转换为向量存储在向量数据库中。</p><p>Retrieval</p><p>RAG系统会将用户请求(query)转换为一个向量表示，然后通过计算查询向量和chunks向量之间的相似度来检索与query最相近的top k个chunks。</p><p>Generation</p><p>将用户提出的查询和所选文档合成为一个连贯的提示，大型语言模型的任务是制定响应。在正在进行的对话情况下，任何现有的历史都会可以集成到提示中，是模型能够有效参与多轮对话交互。</p><p>检索阶段的挑战：准确率和召回率；导致错误或不相关的chunk，以及缺少关键信息。</p><p>生成阶段的困难：出现幻觉</p><p>增强阶段的障碍：检索信息与不同任务结合可能具有挑战性，有时会导致输出不连贯。</p><h4 id="Advanced-RAG"><a href="#Advanced-RAG" class="headerlink" title="Advanced RAG"></a>Advanced RAG</h4><p>相比于Naive RAG，Advanced RAG专注于提高检索质量，运用了<strong>预检索</strong>pre-retrieval 和 <strong>后检索</strong>post-retrieval策略。</p><p>pre-retrieval重点关注优化索引结构和原始查询，优化索引的目标是提高被索引的内容的质量。</p><p>post-retrieval阶段主要是整合有效查询，主要的方法包括chunks重排和上下文压缩。重新排序检索到的信息以将最相关的内容重新定位到提示的边缘是关键策略。</p><h4 id="Modular-RAG"><a href="#Modular-RAG" class="headerlink" title="Modular RAG"></a>Modular RAG</h4><p>相比于前两种范式，模块化RAG的适应性和多功能性得到提高。</p><p>方法：添加一个搜索模块进行相似度搜索，并通过微调细化检索器。<strong>重组RAG模块+重排RAG管道</strong>来解决目前新的挑战，引入额外组件提高检索和处理能力。</p><p>创新：Rewrite-Retrieve-Read Model 利用LLM的能力通过重写模块和LLM反馈机制来改进检索查询，以更新重写模型，提高任务性能。</p><p>Generate-Read 用LLM生成的内容替换传统的检索</p><p>ReciteRead 强调从模型权重中检索，增强了模型处理知识密集型任务的能力</p><p>调整：Demonstrate-Search-Predict(DSP)框架和迭代的Retrieve-Read-Retrieve-Read流使用增强了模块的协同复杂理解。</p><h4 id="RAG与微调"><a href="#RAG与微调" class="headerlink" title="RAG与微调"></a>RAG与微调</h4><p>RAG通过提供实时知识更新和有效利用具有高可解释性的知识源，在动态环境中表现出色。然而，在检索方面有更高的延迟和伦理考虑。</p><p>RAG 和 微调技术之间的选择取决于应用程序上下文中数据动态、定制和计算能力的具体需求。RAG 和 微调技术不是互斥的，可以相互补充，增强了模型在不同层次上的能力。在某些情况下，它们的组合使用可能会导致最佳性能。涉及RAG和微调技术的优化过程可能需要多次迭代才能获得满意的结果。</p><h3 id="检索-RETTRIEVAL"><a href="#检索-RETTRIEVAL" class="headerlink" title="检索-RETTRIEVAL"></a>检索-RETTRIEVAL</h3><h4 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h4><h4 id="Semi-structured-data"><a href="#Semi-structured-data" class="headerlink" title="Semi-structured data"></a>Semi-structured data</h4><p>特别关注对于<strong>半结构化数据</strong>的处理分析。典型的半结构化数据例如PDF包括文本和表信息。</p><p>有两大原因导致传统RAG系统在处理半结构化数据时面临挑战：</p><ol><li>文本的切分会不经意地拆分表格，导致检索过程中的数据损坏</li><li>表与数据的结合会使语义相似度检索变得更加复杂</li></ol><p>目前，处理半结构化数据的方法是<strong>利用LLM的编码能力在数据库表上执行Text-2-SQL</strong>查询，或者<strong>将表格转化为文本格式</strong>，使用基于文本的处理方法进行分析。</p><p><strong>所有的方法目前都不是最优的，该领域还有大量的研究机会。</strong></p><h4 id="Structured-data"><a href="#Structured-data" class="headerlink" title="Structured data"></a>Structured data</h4><p>图检索使GNN神经网络、LLM与RAG相结合，通过LLM的软提示来增强图形理解和问答能力，并使用Prize-Collecting Steiner Tree进行优化图检索的结果。</p><h4 id="LLMs-Generated-Content"><a href="#LLMs-Generated-Content" class="headerlink" title="LLMs-Generated Content"></a>LLMs-Generated Content</h4><p>LLM 生成的上下文通常包含更准确的答案，因为其与因果语言建模的预训练目标能更好地对齐。</p><h4 id="Retrieval-Granularity"><a href="#Retrieval-Granularity" class="headerlink" title="Retrieval Granularity"></a>Retrieval Granularity</h4><p><strong>粗粒度检索单元</strong>理论上可以为问题提供更多相关信息，但它们也可能包含冗余内容，这可能会分散下游任务中的检索器和语言模型。</p><p>另一方面，<strong>细粒度检索单元</strong>粒度增加了检索的负担，不能保证语义完整性并满足所需的知识。</p><p>选择恰当的检索粒度是一个简单的策略用来提高检索和下游任务的表现。</p><p>检索粒度从粗到细包括：Token, Phrase, Sentence, Proposition, Chunks, Document。将Propositions作为检索单元可以提高检索的相关性和精准度。</p><h3 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a>索引优化</h3><p>在索引阶段，文档将被处理、分割并转换为要存储在向量数据库中的嵌入。索引的构造质量决定了是否可以在检索阶段获取正确的上下文。</p><h4 id="分块策略"><a href="#分块策略" class="headerlink" title="分块策略"></a>分块策略</h4><p>分块常用的方法是将文档分为不同的标记的chunks。</p><p>分块需要在语义完整性和上下文长度之间进行权衡trade-off。更长的块会包含更长的上下文，但是噪声会增加、处理时间也会增加；短块包含的噪声小，但是能包含的上下文信息也更少。</p><p>于是后面提出了以句子作为检索单元，前后句被提供作为LLM的上下文内容。</p><h4 id="元数据附加"><a href="#元数据附加" class="headerlink" title="元数据附加"></a>元数据附加</h4><p>在检索过程中为文档时间戳分配不同的权重可以实现时间感知的RAG，确保知识的新鲜度并避免过时的信息。</p><p>元数据也可以被人工构建(添加段落摘要以及引入假设问题)。具体来说，使用 LLM 生成文档可以回答的问题，然后计算检索过程中原始问题和假设问题之间的相似度，以减少问题和答案之间的语义差距。</p><h3 id="查询优化"><a href="#查询优化" class="headerlink" title="查询优化"></a>查询优化</h3><p>问题本身的复杂性、语义模糊性都是查询过程中遇到的困难。</p><p>查询优化的方法主要有三大类：</p><p>1.查询扩展</p><ul><li>多路查询</li><li>子查询</li><li>Chain-of-Verification(CoVe)</li></ul><p>2.查询转换-查询重写</p><p>3.查询路由</p><h4 id="嵌入-Embedding"><a href="#嵌入-Embedding" class="headerlink" title="嵌入-Embedding"></a>嵌入-Embedding</h4><p>怎么理解嵌入？</p><p>Embedding 是将离散的非结构化数据(图片、视频、音频、文本)通过Embedding Model转换为连续的向量表示的技术。</p><p>Embedding 常常用于将文本数据中的单词、句子或文档映射为固定长度的实数向量，使得文本数据能够在计算机中被更好地处理和理解。通过 Embedding，每个单词或句子都可以用一个实数向量来表示，这个向量中包含了该单词或句子的语义信息。</p><p>RAG系统中，检索是通过计算嵌入问题和文档块之间的相似度实现的。</p><p>没有最好的答案去回答“要使用哪一个嵌入模型”，然而，对于不同的问题可以有不同的方法。</p><h4 id="增强-AUGMENTATION-PROCESS-IN-RAG"><a href="#增强-AUGMENTATION-PROCESS-IN-RAG" class="headerlink" title="增强-AUGMENTATION PROCESS IN RAG"></a>增强-AUGMENTATION PROCESS IN RAG</h4><p>增强的过程主要侧重于优化检索的过程，这一部分介绍了三大检索增强的过程：迭代式检索、递归式检索、自适应检索。</p><p>迭代检索涉及检索和生成之间交替，允许在每一步从知识库中更丰富、更有针对性的上下文。递归检索涉及逐步细化用户查询并将问题分解为子问题，然后通过检索和生成不断解决复杂问题。自适应检索侧重于使 RAG 系统能够自主确定外部知识检索是否必要以及何时停止检索和生成，通常使用 LLM 生成的特殊标记来控制。</p><h4 id="生成-GENERATION"><a href="#生成-GENERATION" class="headerlink" title="生成-GENERATION"></a>生成-GENERATION</h4><p>在检索后，将所有检索到的信息直接输入到LLM中回答问题并不是一个好的实践。</p><h3 id="上下文配置"><a href="#上下文配置" class="headerlink" title="上下文配置"></a>上下文配置</h3><p>过长的上下文信息会导致LLM“忽视中间段落”，与人类一样，LLM 往往只关注长文本的开头和结尾，同时忘记中间部分。因此，在 RAG 系统中，我们通常需要进一步处理检索到的内容。</p><p>重排：从根本上重新排序对文档(chunks)块进行重新排序以首先突出最相关的结果，有效地减少整体文档池，在信息检索中切断双重目的，充当增强器和过滤器，为更精确的语言模型处理提供细化的输入。</p><p>上下文选择&#x2F;压缩：对RAG过程的一个误解是相信尽可能多地检索相关文档并用长检索提示包含他们是有好处的。然而，大量的信息也会带来大量的干扰，削弱大语言模型对于关键信息的敏锐度。</p><p>压缩方法包括检测并移除不重要的tokens，将上下文转化为人类很难理解但是LLM很好理解的形式。</p><h3 id="LLM微调"><a href="#LLM微调" class="headerlink" title="LLM微调"></a>LLM微调</h3><p>当LLM缺少特定领域的数据的时候，外部知识可以被提供通过微调技术。</p><p>微调的另一个好处是可以控制模型的输入和输出。它可以让LLM适应特定的数据格式和按照指示以特定风格生成响应。</p><p>通过强化学习将LLM输出与人类或检索器偏好对齐是一种潜在的方法。除了与人类偏好对齐外，还可以与微调模型和检索器的偏好保持一致。</p><p>当环境防止访问强大的专有模型或更大的参数开源模型时，一种简单有效的方法是提取更强大的模型（例如 GPT-4）。</p><h3 id="下游任务与评估"><a href="#下游任务与评估" class="headerlink" title="下游任务与评估"></a>下游任务与评估</h3><h4 id="下游任务"><a href="#下游任务" class="headerlink" title="下游任务"></a>下游任务</h4><p>RAG的核心任务仍然是<strong>问答</strong>(QA)，QA包括传统的单步&#x2F;多步问答、多项选择、特定领域问答、长文本场景问答。</p><p>RAG也不断扩展到多个下游任务，如信息提取(IE)、对话生成、代码搜索等。</p><h4 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h4><p><strong>上下文相关性和噪声鲁棒性</strong>对于评估检索质量很重要，而答案忠实度、答案相关性、负拒绝、信息集成和反事实鲁棒性对于评估生成质量很重要。</p><h3 id="RAG面临主要挑战和未来前景"><a href="#RAG面临主要挑战和未来前景" class="headerlink" title="RAG面临主要挑战和未来前景"></a>RAG面临主要挑战和未来前景</h3><h4 id="RAG-VS-长上下文"><a href="#RAG-VS-长上下文" class="headerlink" title="RAG VS 长上下文"></a>RAG VS 长上下文</h4><p>目前，LLM 可以毫不费力地管理超过 200,000 个标记的上下文。这也引发了关于当LLM不受上下文限制的时候是否还需要RAG的讨论。</p><p>对于RAG过程，整个检索和推理过程是可观察的，而仅依靠长上下文生成仍然是一个黑匣子。在超长上下文的背景下开发新的 RAG 方法是未来研究趋势之一。</p><h4 id="RAG鲁棒性"><a href="#RAG鲁棒性" class="headerlink" title="RAG鲁棒性"></a>RAG鲁棒性</h4><p>检索过程中噪声或矛盾信息的存在会对RAG的输出质量产生不利影响。这种情况被比喻地称为“Misinformation 可以比根本没有信息更糟糕”。</p><p>提高RAG对这种对抗性或反事实输入的抵抗力正在获得研究势头，已成为一个关键的性能指标。</p><h4 id="混合方法"><a href="#混合方法" class="headerlink" title="混合方法"></a>混合方法</h4><p>将RAG与微调技术相结合正在成为领先策略，确定RAG与微调最佳整合取决于是顺序、交替还是端到端的训练。</p><p>另一个趋势是将特殊功能的<strong>小语言模型SLM</strong>引入RAG，并通过RAG系统进行微调。</p><h4 id="scaling-laws-of-RAG"><a href="#scaling-laws-of-RAG" class="headerlink" title="scaling laws of RAG"></a>scaling laws of RAG</h4><p>基于RAG的端到端模型和预训练模型仍然是当前研究人员的重点之一。</p><h4 id="Production-Ready-RAG"><a href="#Production-Ready-RAG" class="headerlink" title="Production-Ready RAG"></a>Production-Ready RAG</h4><p>然而，提高检索效率，提高大型知识库的文档召回率，保证数据安全，这些地方仍然有待解决的挑战。</p><p>RAG技术在特殊方向的趋势：1.特定需求的定制。2.降低最初的学习曲线来简化RAG使用。3.优化RAG来更好的服务生产环境。</p><h4 id="多模态RAG"><a href="#多模态RAG" class="headerlink" title="多模态RAG"></a>多模态RAG</h4><p>RAG在图像、音频视频、编码领域的应用。</p><h3 id="个人阅读总结"><a href="#个人阅读总结" class="headerlink" title="个人阅读总结"></a>个人阅读总结</h3><h4 id="通原理"><a href="#通原理" class="headerlink" title="通原理"></a>通原理</h4><p>对于RAG技术栈的原理自己在脑海中应该有了一定的轮廓，接下来就是重点学习一些技术细节，比如<strong>微调技术、嵌入技术</strong>，更多去关注下游任务实践与部署应用。</p><p>练实践带动并反作用于学习，真正从实践中体会部署技术、微调技术、训练技术。</p><p><img src="/Users/liuhe/Desktop/946bcd353f159e59505642241522ab1e.jpg" alt="946bcd353f159e59505642241522ab1e"></p><h5 align="center">RAG链路图</h5><h3 id="知趋势"><a href="#知趋势" class="headerlink" title="知趋势"></a>知趋势</h3><h3 id="着力点"><a href="#着力点" class="headerlink" title="着力点"></a>着力点</h3><p>多模态RAG(Multi-modal RAG)、半结构化数据检索(处理半结构化数据的方法优化)、鲁棒性(RAG的对抗性或反事实输入的抵抗力)</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch and Deep-learning NoteBook</title>
    <link href="/2025/09/25/Pytorch%20and%20Deep-learning%20NoteBook/"/>
    <url>/2025/09/25/Pytorch%20and%20Deep-learning%20NoteBook/</url>
    
    <content type="html"><![CDATA[<h2 id="参考学习资料"><a href="#参考学习资料" class="headerlink" title="参考学习资料"></a>参考学习资料</h2><p>小土堆-pytorch学习教程</p><p><a href="https://www.bilibili.com/video/BV1hE411t7RN/?p=10&spm_id_from=333.1007.top_right_bar_window_history.content.click&vd_source=f093c3d64ba399e149cbffa6cd31a7b0">https://www.bilibili.com/video/BV1hE411t7RN/?p=10&amp;spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=f093c3d64ba399e149cbffa6cd31a7b0</a></p><p>李沐-动手学深度学习：</p><p><a href="https://www.bilibili.com/video/BV1wM4m117mp/?spm_id_from=333.337.search-card.all.click&vd_source=f093c3d64ba399e149cbffa6cd31a7b0">https://www.bilibili.com/video/BV1wM4m117mp/?spm_id_from=333.337.search-card.all.click&amp;vd_source=f093c3d64ba399e149cbffa6cd31a7b0</a></p><p>李宏毅深度学习教程LeeDL-Tutorial（苹果书）：</p><p><a href="https://github.com/datawhalechina/leedl-tutorial?tab=readme-ov-file">https://github.com/datawhalechina/leedl-tutorial?tab=readme-ov-file</a></p><p>张贤同学pytorch学习笔记：</p><p><a href="https://pytorch.zhangxiann.com/">https://pytorch.zhangxiann.com/</a></p><p>《pytorch实用教程(第二版)》</p><p><a href="https://tingsongyu.github.io/PyTorch-Tutorial-2nd/">https://tingsongyu.github.io/PyTorch-Tutorial-2nd/</a></p><h2 id="conda常用指令"><a href="#conda常用指令" class="headerlink" title="conda常用指令"></a>conda常用指令</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">创建环境</span><br>conda create -n your_env_name python=x.x(x.x为python版本)<br>eg: conda create -n pytorch_tutorial python=3.7<br><span class="hljs-meta prompt_"># </span><span class="language-bash">激活环境</span><br>source avtivate your_env_name<br>eg: source activate pytorch_tutorial<br><span class="hljs-meta prompt_"># </span><span class="language-bash">推出环境</span><br>source deactivate<br><span class="hljs-meta prompt_"># </span><span class="language-bash">删除环境</span><br>conda remove -n your_env_name -all<br>eg: conda remove -n pytorch_tutorial -all<br><span class="hljs-meta prompt_"># </span><span class="language-bash">查看已有的虚拟环境</span><br>conda env list / conda info -e<br></code></pre></td></tr></table></figure><h2 id="PyTorch-CookBook"><a href="#PyTorch-CookBook" class="headerlink" title="PyTorch CookBook"></a>PyTorch CookBook</h2><h3 id="PyTorch安装"><a href="#PyTorch安装" class="headerlink" title="PyTorch安装"></a>PyTorch安装</h3><p>CPU版本的安装：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install torch torchvision torchaudio<br></code></pre></td></tr></table></figure><p>GPU版本：</p><p>安装指令可以去官网查看与之适配的CUDA版本，选择合适的操作系统、编程语言与CUDA版本安装即可</p><p><a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a></p><h3 id="PyTorch常用子文件"><a href="#PyTorch常用子文件" class="headerlink" title="PyTorch常用子文件"></a>PyTorch常用子文件</h3><p>执行完pip install torch后，Torch的安装路径为：&#x2F;Users&#x2F;mungeryang&#x2F;anaconda3&#x2F;lib&#x2F;python3.11&#x2F;site-packages&#x2F;torch，在程序中import torch其实是从安装路径中进行导入。</p><p>torch中重要的组件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">_pycache: 该文件夹存放python解释器生成的字节码,目的是通过牺牲一定的存储空间来提高加载速度<br>_C: 辅助C语言代码调用的一个模块,PyTorch的底层计算代码采用的是C++语言编写，并封装成库，供pytorch的python语言进行调用<br>include: 存放着上面描述底层计算所需的C++代码<br>lib: lib文件夹下包含大量的.lib .dll文件（分别是静态链接库和动态链接库）,torch文件夹中98%内容都在lib中<br>autograd: pytorch的核心模块与概念，它实现了梯度的自动求导，开发人员只需编写前向传播代码，反向传播部分由autograd自动实现<br>nn: 使用频率最高的模块，搭建网络的网络层就在nn.modules里边<br>onnx: pytorch模型转换到onnx模型表示的核心模块<br>optim: 优化使用的方法函数，都在optim文件夹中<br>utils: utils是各种软件工程中常见的文件夹，包含了各类常用工具，其中比较关键的是data文件夹，tensorboard文件夹<br>datasets: 常用的数据集写的数据读取函数，例如常见的cifar, coco, mnist,svhn,voc都是有对应的函数支持<br>torchvision:<br>models: 它里边存放了经典的、可复现的、有训练权重参数可下载的深度学习模型<br>ops: 视觉任务特殊的功能函数<br>transforms: transforms是pytorch自带的图像预处理、增强、转换工具<br></code></pre></td></tr></table></figure><p>&#x3D;&#x3D;<em>菜鸟使用pytorch实现图像分类任务时可能考虑到的任务点</em>&#x3D;&#x3D;：</p><p>图像数据是哪用一行代码读取进来的？</p><p>transforms.Compose是如何工作对图像数据进行转换的？</p><p>ToTensor又有哪些操作？</p><p>如何编写Dataset？</p><p>DataLoader有什么功能？如何使用？有什么需要注意的？</p><p>模型如何按自己的数据流程搭建？</p><p>nn有哪些网络层可以调用？</p><p>损失函数有哪些？</p><p>优化器是如何更新model参数的？</p><p>学习率调整有哪些方法？如何设置它们的参数？</p><p>model.train()与model.eval()作用是什么？</p><p>optimizer.zero_grad()是做什么？为什么要梯度清零？</p><p>scheduler.step() 作用是什么？应该放在哪个for循环里？</p><h2 id="核心板块-Tensor"><a href="#核心板块-Tensor" class="headerlink" title="核心板块 - Tensor"></a>核心板块 - Tensor</h2><p>Pytorch中核心的数据结构就是张量——Tensor</p><p>张量表示的是一个多维数组，它是标量、向量、矩阵的拓展。标量(Scaler)是零维张量，向量(Vector)是一维张量，矩阵(Matrix)是二维张量，一个RGB数组是三维张量。</p><p>torch.Tensor的八大属性：</p><ol><li>data: 多维数组</li><li>dtype: 多维数组的数据类型</li><li>shape: 多维数组的形状</li><li>device: tensor所在设备，cpu或GPU</li><li>grad, grad_fn, is_leaf, requires_grad: 梯度计算中需要的</li></ol><p>Pytorch训练的五大要素：数据、模型、损失函数、优化器、迭代训练</p><p>多维数组是主要的数据处理形式</p><h2 id="数据模块-DataSet、DataLoader、transforms"><a href="#数据模块-DataSet、DataLoader、transforms" class="headerlink" title="数据模块 - DataSet、DataLoader、transforms"></a>数据模块 - DataSet、DataLoader、transforms</h2><p>DataSet是一个抽象基类，提供给用户自定义数据读取方式，核心在于<strong>getitem</strong>方法中对数据的处理。</p><p>DataLoader是pytorch数据加载核心，包括了大乱数据、采样机制、多进程数据加载、组装Batch。</p><h3 id="DataSet类代码实战"><a href="#DataSet类代码实战" class="headerlink" title="DataSet类代码实战"></a>DataSet类代码实战</h3><p>虽然DataLoader是pytorch核心数据模块，但是改动最多与原数据最为接近的是DataSet。</p><p>DataSet类中核心功能：</p><ol><li><strong>getitem</strong>：实现读取一个样本的功能。通常是传入索引，然后实现从磁盘中读取数据，并行处理数据，返回样本数据。getitem返回的数据会在dataloader中组装成一个batch。</li><li><strong>len</strong>：返回数据集大小</li></ol><p>Dataset负责与磁盘打交道，将磁盘上的数据读取并预处理好，提供给DataLoader，而DataLoader只需要关心如何组装成批数据，以及如何采样。</p><h3 id="DataLoader类代码实战"><a href="#DataLoader类代码实战" class="headerlink" title="DataLoader类代码实战"></a>DataLoader类代码实战</h3><h2 id="模型板块"><a href="#模型板块" class="headerlink" title="模型板块"></a>模型板块</h2><p>nn.Module</p><h2 id="创建简单的神经网络"><a href="#创建简单的神经网络" class="headerlink" title="创建简单的神经网络"></a>创建简单的神经网络</h2><p>使用Pytorch创建一个神经网络意味着创建一个新的类</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> SGD<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BasicNet</span>(nn.Module):<br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-built_in">super</span>(BasicNet,<span class="hljs-variable language_">self</span>).__init__()<br>    <br>    <span class="hljs-comment">#初始化所有的权重和偏差</span><br>    <span class="hljs-variable language_">self</span>.w00 = nn.Parameter(torch.tensor(<span class="hljs-number">1.7</span>), requires_gard = <span class="hljs-literal">False</span>)<br>    <span class="hljs-variable language_">self</span>.b00 = nn.Parameter(torch.tensor(-<span class="hljs-number">0.85</span>), requires_gard = <span class="hljs-literal">False</span>)<br>    <span class="hljs-variable language_">self</span>.w01 = nn.Parameter(torch.tensor(-<span class="hljs-number">40.8</span>), requires_gard = <span class="hljs-literal">False</span>)<br>    <br>    <span class="hljs-variable language_">self</span>.w10 = nn.Parameter(torch.tensor(<span class="hljs-number">12.6</span>), requires_gard = <span class="hljs-literal">False</span>)<br>    <span class="hljs-variable language_">self</span>.b10 = nn.Parameter(torch.tensor(<span class="hljs-number">0.0</span>), requires_gard = <span class="hljs-literal">False</span>)<br>    <span class="hljs-variable language_">self</span>.w11 = nn.Parameter(torch.tensor(<span class="hljs-number">2.7</span>), requires_gard = <span class="hljs-literal">False</span>)<br>    <br>    <span class="hljs-variable language_">self</span>.final_bias = nn.Parameter(torch.tensor(-<span class="hljs-number">16.0</span>), requires_grad = <span class="hljs-literal">False</span>)<br>    <br>  <span class="hljs-comment"># 前向传播</span><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,<span class="hljs-built_in">input</span></span>):<br>    <br>    input_to_top_relu = <span class="hljs-built_in">input</span> * <span class="hljs-variable language_">self</span>.w00 + <span class="hljs-variable language_">self</span>.b00<br>    top_relu_output = F.relu(input_to_top_relu)<br>    scaled_top_relu_output = top_relu_output * <span class="hljs-variable language_">self</span>.w01<br>    <br>    input_to_buttom_relu = <span class="hljs-built_in">input</span> * <span class="hljs-variable language_">self</span>.w10 + <span class="hljs-variable language_">self</span>.b10<br>    buttom_relu_output = F.relu(input_to_buttom_relu)<br>    scaled_buttom_relu_output = buttom_relu_output * <span class="hljs-variable language_">self</span>.w11<br>    <br>    input_to_final_relu = scaled_top_relu_output + scaled_buttom_relu_output +       <span class="hljs-variable language_">self</span>.final_bias<br>    output = F.relu(input_to_final_relu)<br>    <br>    <span class="hljs-keyword">return</span> output<br>  <br>input_doses = torch.linspace(start = <span class="hljs-number">0</span>,end = <span class="hljs-number">1</span>,step = <span class="hljs-number">11</span>)<br>model = BasicNet()<br>output = model(input_doses)<br></code></pre></td></tr></table></figure><p>从创建网络到训练的完整流程：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 创建神经网络</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BasicNet</span>(nn.Module):<br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>    <span class="hljs-built_in">super</span>(BasicNet,<span class="hljs-variable language_">self</span>).__init__()<br>    <br>    <span class="hljs-comment">#初始化所有的权重和偏差</span><br>    <span class="hljs-variable language_">self</span>.w00 = nn.Parameter(torch.tensor(<span class="hljs-number">1.7</span>), requires_gard = <span class="hljs-literal">False</span>)<br>    <span class="hljs-variable language_">self</span>.b00 = nn.Parameter(torch.tensor(-<span class="hljs-number">0.85</span>), requires_gard = <span class="hljs-literal">False</span>)<br>    <span class="hljs-variable language_">self</span>.w01 = nn.Parameter(torch.tensor(-<span class="hljs-number">40.8</span>), requires_gard = <span class="hljs-literal">False</span>)<br>    <br>    <span class="hljs-variable language_">self</span>.w10 = nn.Parameter(torch.tensor(<span class="hljs-number">12.6</span>), requires_gard = <span class="hljs-literal">False</span>)<br>    <span class="hljs-variable language_">self</span>.b10 = nn.Parameter(torch.tensor(<span class="hljs-number">0.0</span>), requires_gard = <span class="hljs-literal">False</span>)<br>    <span class="hljs-variable language_">self</span>.w11 = nn.Parameter(torch.tensor(<span class="hljs-number">2.7</span>), requires_gard = <span class="hljs-literal">False</span>)<br>    <br>    <span class="hljs-variable language_">self</span>.final_bias = nn.Parameter(torch.tensor(<span class="hljs-number">0.0</span>), requires_grad = <span class="hljs-literal">True</span>)<br>    <br>  <span class="hljs-comment"># 前向传播</span><br>  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,<span class="hljs-built_in">input</span></span>):<br>    <br>    input_to_top_relu = <span class="hljs-built_in">input</span> * <span class="hljs-variable language_">self</span>.w00 + <span class="hljs-variable language_">self</span>.b00<br>    top_relu_output = F.relu(input_to_top_relu)<br>    scaled_top_relu_output = top_relu_output * <span class="hljs-variable language_">self</span>.w01<br>    <br>    input_to_buttom_relu = <span class="hljs-built_in">input</span> * <span class="hljs-variable language_">self</span>.w10 + <span class="hljs-variable language_">self</span>.b10<br>    buttom_relu_output = F.relu(input_to_buttom_relu)<br>    scaled_buttom_relu_output = buttom_relu_output * <span class="hljs-variable language_">self</span>.w11<br>    <br>    input_to_final_relu = scaled_top_relu_output + scaled_buttom_relu_output + <span class="hljs-variable language_">self</span>.final_bias<br>    output = F.relu(input_to_final_relu)<br>    <br>    <span class="hljs-keyword">return</span> output<br><br><span class="hljs-comment"># 定义优化器</span><br>optimizer = SGD(model.parameters(),lr = <span class="hljs-number">0.1</span>)<br><br><span class="hljs-comment"># 模型训练</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>  <br>  total_loss = <span class="hljs-number">0.0</span><br>  <br>  <span class="hljs-keyword">for</span> iteration <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(inputs)):<br>    input_i = inputs[iteration]<br>    label_i = labels[iteration]<br>    output_i = model(input_i)<br>    <br>    loss = (output_i - label_i) ** <span class="hljs-number">2</span><br>    <br>    loss.backward()<br>    total_loss += <span class="hljs-built_in">float</span>(loss)<br>    <br><span class="hljs-keyword">if</span>(total_loss &lt; <span class="hljs-number">0.0001</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Num steps:&quot;</span> + <span class="hljs-built_in">str</span>(epoch))<br>  <span class="hljs-keyword">break</span><br>  optimizer.step()<br>  optimizer.zero_grad()<br>  <br>  <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Step: &quot;</span> + <span class="hljs-built_in">str</span>(epoch) + <span class="hljs-string">&quot;Final bias: &quot;</span> + <span class="hljs-built_in">str</span>(model.final_bias) + <span class="hljs-string">&quot;\n&quot;</span>)<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>经贸三年</title>
    <link href="/2025/09/10/%E7%BB%8F%E8%B4%B8%E4%B8%89%E5%B9%B4/"/>
    <url>/2025/09/10/%E7%BB%8F%E8%B4%B8%E4%B8%89%E5%B9%B4/</url>
    
    <content type="html"><![CDATA[<p>开学一周，遇见了很多优秀的同学。依稀记得，第一次开班会的时候，大家在做自我介绍，有的人会说自己的本科毕业院校是哪里。还有第一次和导师见面的时候，老师问了我们的本科学校，我留心关注了一下，我的本科学校应该是“倒数”的，起码在我们组是“倒数第一”。说实话，本科院校说出来其实是不自信的，最终，我还是大大方方、很坦然的说了出来。此时此刻，彷佛就像刚步入高中，步入沧县中学那个优秀的环境中，第一次感受到人外有人，天外有天这句话的份量。但是，唯一不同的是，我的心态和那时有了很大的变化。</p><p>刚从乡镇走出来，步入县中的时候，那时候身边都是比自己优秀的人。说实话，那三年过的非常迷茫和压抑。初中的时候，你在学校是“呼风唤雨的”，但是到了一个更大的环境中、一个竞争更激烈的环境中，你彷佛就迷失了自己。那几年你会发现，你好像无论怎么努力、怎么使劲学都没办法赶超周围的人，你一直在盲目的进行分数的“攀比”。学业学业跟不上、擅长的体育也不再是特长、个人感情不顺利…真就想掉入深渊一样，周围全是黑暗，看不到一丝希望与光亮。</p><p>本科的时候，其实是很不满意的，可能就是因为开始的时候觉得自己很强，和现在对比落差很大。唯一重要的是，这四年，我觉着你一直在<em><strong>找自己</strong></em>****。找自己就是客观坦然的面对自己，重新认识自己，不能好高骛远，从容地面对自己的优点和缺点，三人行必有我师焉，你也在时时刻刻向身边优秀的人学习。真诚、勇敢、向上社交。</p><p>好了，话说回来了，来到研究生阶段，又是到了一个更大的环境中、一个竞争更激烈的环境中，彷佛是轮回。我想，此时的你一定不同于高中时期的你，你的心里一定多了几分淡定与从容。就随着这份淡定与从容，继续向前吧！千磨万击还坚劲，任尔东西南北风。走好自己的路，心安即强大。</p><p>前路漫漫，忘君珍重、珍惜。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>毛选及相关</title>
    <link href="/2025/06/30/%E6%AF%9B%E9%80%89%E5%8F%8A%E7%9B%B8%E5%85%B3/"/>
    <url>/2025/06/30/%E6%AF%9B%E9%80%89%E5%8F%8A%E7%9B%B8%E5%85%B3/</url>
    
    <content type="html"><![CDATA[<h1 id="唯物辩证法的基本规律"><a href="#唯物辩证法的基本规律" class="headerlink" title="唯物辩证法的基本规律"></a>唯物辩证法的基本规律</h1><p>《大众哲学》——艾思奇</p><p>唯物主义者必须让自己养成一种习惯：遇到任何事情、任何问题，都能够认真地做系统周密的调查研究，把事物本身的规律寻找出来，然后按照规律去办事，去解决问题，去指导工作，使事情办的好，问题得以顺利解决，工作做的有成绩，不至于碰钉子，或者至少不碰大钉子。</p><p>不如意和碰钉子的原因是因为我们的主观意愿和事物的客观规律不符合！</p><p>世界上一切事物，是在我们的主观心意之外独立存在着的，它们的发展变化情况不是依赖我们的心意为转移的。世界上的事情，绝对不是我们想要怎样就怎样的，相反的，常常是我们希望这样，而偏偏事实上就不会这样。考试失利、投资失败、分手失恋、失业…</p><p>“凡事不会无缘无故的发生”，这就是“无风不起浪”这一个成语包含的最主要的哲学思想，这种思想在每个人的头脑中普遍存在着，其实每个人都相信，一切事物的发生，它的出现总有一定的原因，一定道理。一切事物不会凭空产生和消失，任何事物都有它发生、发展和没落的过程。</p><h1 id="实践论"><a href="#实践论" class="headerlink" title="实践论"></a>实践论</h1><p>用联系和运动的观点看待事物的发展</p><h1 id="矛盾论"><a href="#矛盾论" class="headerlink" title="矛盾论"></a>矛盾论</h1><p>对立统一</p><p>在研究一切问题的时候，注意到事物发展的曲折性，不要把事物的发展，看作一条直线上升，而没有任何迂回、后退、停滞的形式，也不要把任何事物的发展看作是简单的循环，而不注意它由低级到高级的上升。事物的发展是曲折的，螺旋式上升的。</p><h2 id="战略战术分析"><a href="#战略战术分析" class="headerlink" title="战略战术分析"></a>战略战术分析</h2><p>中国红色政权存在的原因</p><p>井冈山斗争</p><p>论持久战</p><p>抗日游击战争的战略问题</p><h1 id="预见力与原则"><a href="#预见力与原则" class="headerlink" title="预见力与原则"></a>预见力与原则</h1><h2 id="原则"><a href="#原则" class="headerlink" title="原则"></a>原则</h2><p>1.独立自主</p><p>独立自主、自力更生，在此基础之上来尽可能多的争取外援。合理的看待外援也是一种辩证法。</p><p>只有坚持独立自主，自己把自己照顾好，让自己强大起来，才能帮助到父母和家人，才能真正帮助到朋友。否则都是假的。</p><p>白手起家还需要独立自主。</p><p>爱别人，首先爱自己。</p><p>让步一定是积极的而不是消极的，本质是为了更好的合作，同样，让步也是有一定界限的。</p><p>2.实事求是</p><p>实事——客观存在的一切事物</p><p>求——调查研究</p><p>是——客观事物的内部联系，即规律性</p><p>实事：研究一切问题都要从实际事物出发，而不是从理论、概念、观点和定义出发。</p><p>求是：研究事物的规律，总结事物的规律，然后用规律指导行动。</p><p>3.群众路线</p><p>群众路线就是不脱离不脱离社会实际，因为群众是构成社会实际最基础的基础。</p><h2 id="预见力"><a href="#预见力" class="headerlink" title="预见力"></a>预见力</h2><p>什么事预见力？就是将矛盾发展演变成种种趋势加以判断，然后对自己主观能动性加以判断，最后得出事物发展的最大可能性。并且把这种可能性和必然性指出来，辅助以相应的对策，最后取得胜利。</p><p>在复杂的事物也是由简单事物的叠加组成的，提高预见力与洞察力，本质上就是需要我们擅长事物的矛盾分析和条件分析。</p><h1 id="成事的科学原理"><a href="#成事的科学原理" class="headerlink" title="成事的科学原理"></a>成事的科学原理</h1><p>分析清楚事物的矛盾，通过调查研究得出干这件事需要哪些条件，然后确定现在是否时机已经成熟们是否具备这样的条件，之后就是发挥主观能动行去创造条件，最终把事情尽可能的按照自己想的那样去办成。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>张宇智慧箴言</title>
    <link href="/2025/05/01/%E5%BC%A0%E5%AE%87%E6%99%BA%E6%85%A7%E7%AE%B4%E8%A8%80/"/>
    <url>/2025/05/01/%E5%BC%A0%E5%AE%87%E6%99%BA%E6%85%A7%E7%AE%B4%E8%A8%80/</url>
    
    <content type="html"><![CDATA[<h2 id="别害怕"><a href="#别害怕" class="headerlink" title="别害怕"></a>别害怕</h2><p>不要试图掌控自己的奋斗过程，完美自己的各项计划，你会失落的，因为事实上它们并不听你的，你越跟它较劲，它越不听话。<br>不过这没什么，每一个成功，都是源于一段不完美的甚至是很狼狈的奋斗。<br>你只要，摈弃杂念，放下功利，全神贯注，尽力就好，学不完又怎样，考的上就行。好孩子，听话。</p><h2 id="拼搏"><a href="#拼搏" class="headerlink" title="拼搏"></a>拼搏</h2><p>年轻的时候，闯一闯，拼一拼，不要怕什么。实在扛不住了，哭一哭，喊一喊。大不了，回家。<br>不要把感情和情绪放在社会上、网络上，真正值得你在乎的，是表面上希望你出人头地，对你百般挑剔，但在心中却只为你祈求平安健康快乐的家人。<br>孩子们，听话，你逼自己的方法，可能不太对。放下包袱，放下功利，带着爱，带着对这个世界的好奇，去拼搏一下。累了，咱们回家就是了。<br><strong>健健康康，内心阳光</strong>，这八个字，可别弄丢了，丢了，会悔恨终身的。</p><h2 id="最大的敌人是自己"><a href="#最大的敌人是自己" class="headerlink" title="最大的敌人是自己"></a>最大的敌人是自己</h2><p>笛卡尔说，征服你自己，而不是征服世界。孩子们，晚安。</p><h2 id="嗜欲深者天机浅天机浅"><a href="#嗜欲深者天机浅天机浅" class="headerlink" title="嗜欲深者天机浅天机浅"></a>嗜欲深者天机浅天机浅</h2><p>古有云，<strong>无欲则刚</strong>。心思繁杂，欲望太多，则易焦虑，徘徊，无己见，恐非做事之正道。孩子们，务必静心，放下功利，用心为之，方可成之。</p><h2 id="基本功"><a href="#基本功" class="headerlink" title="基本功"></a>基本功</h2><p>有人问基础阶段以什么标准来看自己是不是真的懂了，这个问题我前面也回答过，这里详细说几句。我在课上提到一个人，叫做费曼，他是诺贝尔物理学奖获得者，人们试图研究费曼为什么对问题的理解总是透彻深刻，深得其精髓要义，事实上，费曼自己提出过一个观点：把你所学到的理解到的概念性质和方法讲给一个比如小孩子听（这里是为了确保聆听的人对你所讲述的知之甚少），而且让他尽量听懂，这时你无法用那些复杂的专业性的表达来叙述，在寻找简单通俗易懂的语言的时候，你的大脑在不断的深化对于知识的认识，迫使自己在更深层次上理解它们，这样你一定会停滞在很多地方，而这些地方就是你没有理解的地方。通过努力，把你的知识传递给这个孩子并让他听懂，就是你真的懂了，这就是过关。<br>我前面说到，你一定要会复述我课上对知识的讲解，甚至比我讲的还要简要精炼，这是你迅速融入这个学科思维状态的最佳途径。各位，我再写一会书，你们好好思考下我上面这段话，我是真的希望你们能够懂得如何学习，不要再功利的去卷了，真学东西，学真东西，学会怎么学，不仅为了考研，更为了自己的一生。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>前路漫漫亦灿灿</title>
    <link href="/2025/04/10/%E5%89%8D%E8%B7%AF%E6%BC%AB%E6%BC%AB%E4%BA%A6%E7%81%BF%E7%81%BF/"/>
    <url>/2025/04/10/%E5%89%8D%E8%B7%AF%E6%BC%AB%E6%BC%AB%E4%BA%A6%E7%81%BF%E7%81%BF/</url>
    
    <content type="html"><![CDATA[<p>2025年4月9日，傍晚19:16，故事开始了新篇章。</p><p>翻了翻相册，从2023年3月6号开始，一直到2025年4月9日，整整787天，虽有些遗憾，但经历磕磕绊绊，也算是如愿以偿。</p><p>想说的东西、想表达的东西有好多，但却难以启齿、无从下笔。</p><p>回首这段时光，感谢自己没有放弃自己，感谢一战期间能够自己一个人踏踏实实走完整个过程，感谢二战期间在家备考还能保持相对的自律，往事历历如过眼云烟般浮现在眼前。上一次有这种感觉，还是因为19年底疫情爆发高三开学延期，20年初居家复习的岁月，但现在的心态已与之前很大不同。在整个求学的路上，给我的反思就是，要做成一件事，首先要把自己调整到静音模式，要慎独，踏踏实实的投入进去。想成事，不是每天炸炸呼呼，一天八条朋友圈，恨不得别人不知道我干啥，而是要沉淀、要心静、要忍耐、要坚持，安静的做，成功了再说。</p><p>人性的弱点之一就是<strong>只看结果，不注重过程</strong>。</p><p>你考上研了，考上公了，周围都是欢呼、赞美之词。”牛逼、大佬、太厉害了…”诸如此类的话，会让你沉迷享受，会让你飘飘然忘乎所以。但是，当你没考上、没惊起波澜，周围人并不会关注，甚至会有讥讽、嘲笑不绝于耳。”他不行，他光玩，他就不是那块料…”。所以，自强不息、厚德载物，永远都是法宝，让自己强大起来，让自己内心强大起来，才会在面对这些情况的时候，做到多一份的从容、淡定与坦然。</p><p>今天，也正是小伯伯结婚上差的第一天，可以说是双喜临门吧，家人们知道结果后由衷地为我感到高兴、自豪。感谢家人，没有家人的理解与支持，我没有勇气走好今天的路。</p><p>我的父亲刘红岩，1970年出生于河北省沧州市一个普普通通的农村家庭。爷爷是小学校长，但他小时候学习成绩也不是很好。上学也不是唯一的出路，后来听说尝试过多个行业，最后也算是通过一个小的“创业”，加上自己的努力，日子也是越过越好。</p><p>我的母亲王金垄，1971年出生于河北省沧州市一个普普通通的农村家庭。学习也不是很好，但她和中国传统母亲一样，勤劳、质朴，从小包容我，但自己做错的时候也会批评教育。</p><p>两个人，养育了我、培养了我，因为自己高考考的一塌糊涂，进入了一所民办大学，学费贵，还有这两年因为要买资料车票订酒店等等。以上种种，当我需要钱的时候，老父亲总是那么斩钉截铁地转给我，总是问我钱够不够花，让我没有任何顾虑。钱是好东西，而且钱是干净的，脏的是人心。走正道，好好赚钱、多赚钱永远都是幸福的。</p><p>这两年还要感谢张宇(宇爹)，不确定的日子里一直在通过备考高数舒缓。激发了我对数学的热情，重塑了学科的理解，虽然感觉最稳的科目没有考好，还是有点遗憾，哈哈。</p><p>没有轻舟已过万重山，可能是将登太行雪满山，唯有前路漫漫亦灿灿。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>思旧</title>
    <link href="/2025/04/04/%E6%80%9D%E6%97%A7/"/>
    <url>/2025/04/04/%E6%80%9D%E6%97%A7/</url>
    
    <content type="html"><![CDATA[<p>2025年4月4日，清明节</p><p>今天是清明节，正好复试完在家，就跟着父亲去坟地上烧纸。自己也迷信了一次，在太太(爷爷的母亲)的石碑前，心中默念保佑自己调剂顺利。因为二战复试再一次被刷，一战是综合成绩差0.3分被刷，二战复试比变成了1：2，我不知道是命运的安排还是自己运气不好，最近几年像是一直走下坡路。</p><p>说到我的太太，她的离去也是我第一次经历亲人离世，那天哭肿了眼。</p><p>太太陈立荣，河北省沧州市沧县陈会头人，老爷(太太的配偶)刘安林，字润澜，两人生二子一女，子：清江，清河，女：清兰。老爷在二十几岁的时候被疯狗咬，当时没当回事，之后不幸离世，太太当时27岁，从此自己一个人带着三个孩子守寡。当时在那个年代吃不饱穿不暖，还总遭受一些不公平的对待，去世时92岁，该是怎样的毅力、强大的内心让她坚守了65年，把孩子抚养成人并培养的很优秀。大爷爷刘清江为了减轻家里负担，外出当兵，十年杳无音信，最后当了团长，定居北京。爷爷刘清河，姑奶奶刘清兰，在家都当了老师。</p><p>她去世的时候，我上三年级，还记得去世当天早晨我还去看了她一眼，摸着她的手，还能感受到脉搏，中午上学回来的时候，与她就相隔两世了，这是我第一次经历亲人离世。她对我特别好，最疼的就是我了，平时有吃的东西总是藏在桌子下面的柜子里，只有我去了才会拿出来，现在再去柜子里只有几件衣服了。她脾气也特别好，听村里人说，以前房子后面有一颗桑葚树，他们小时候去树上偷摘桑葚，她看见不但没有不让摘，还说你们小心点，别摔着。其实让我最佩服她的，是她骨子里的那股劲儿。腰摔着的时候，就是坚持不去医院，自己强忍着，慢慢养，但期间手里的活一点没放下，她这一辈子基本没和医院打过交道；早晨起来的时候还经常去周围的树边，双手握着树杈，类似于引体向上，锻炼身体；快九十岁的时候，国庆家里都忙着打枣，中午回去，她已经为我们做熟饭了。她善良，坚强，乐观，没有因为生活的苦难而使她丧失对生活的希望。在经历苦难之后，我看到的依然是她积极的生活态度，没有怨天尤人、没有一蹶不振，永远都给子女树立了好的榜样。其实，这就是我遇到无数困难后，依然有勇气面对的底气来源。</p><p>去年国庆节的时候，大爷爷带着下面的子女们回了趟老家，起因是说她晚上托梦给大爷爷了，说她在那边要盖房子，祭拜完之后，和子女们都在坟前磕了头。大爷爷(也已经86岁了)也是一个念家的人，对老家的感情很深，每次都会把家里的人和事问一遍。这就是所谓的乡愁吧，老家地下埋着祖宗，地上留着自己的童年，很多时候喜欢回老家，不是老家有多好，而是在这片土地上有着不一样的回忆。</p><p>坟头的杂草，黄了又绿，绿了又黄，就像我的思念一样，一年又一年，总也断不了。物是人非事事休，欲语泪先流，逝去的已经逝去，活着的仍要前行。</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
